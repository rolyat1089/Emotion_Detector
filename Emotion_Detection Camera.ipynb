{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import model_from_json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_model.json') as file:\n",
    "    model=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_from_json(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='CategoricalCrossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 48, 48, 32)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 48, 48, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 124)       31868     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 24, 24, 124)       496       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 124)       0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 12, 12, 124)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 12, 12, 124)       61628     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 12, 12, 124)       496       \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 12, 12, 256)       127232    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 124)               31868     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 124)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 250       \n",
      "=================================================================\n",
      "Total params: 546,606\n",
      "Trainable params: 543,742\n",
      "Non-trainable params: 2,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    check,frame=cap.read()\n",
    "    if not check:\n",
    "        break\n",
    "    faces=face_detector.detectMultiScale(frame,1.2,5)\n",
    "    for face in faces:\n",
    "        x,y,w,h=face[0],face[1],face[2],face[3]\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2,1)\n",
    "        img=frame[y:y + h, x:x + w]\n",
    "        img=cv2.resize(frame,(48,48))\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img=np.stack((img,)*3, axis=-1)\n",
    "        img=img/255\n",
    "        img=np.expand_dims(img,axis=0)\n",
    "        pred=model.predict(img)\n",
    "        pred=np.argmax(pred,axis=1)\n",
    "        if(pred==1):\n",
    "            cv2.putText(frame,'Happy',(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,255),2)\n",
    "        else:\n",
    "            cv2.putText(frame,'Angry',(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,255),2)\n",
    "    cv2.imshow('Video',frame)\n",
    "    \n",
    "    if(cv2.waitKey(1) & 0XFF==27):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
